{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0: Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"space_titanic_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa      False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth      False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa      False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa      False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth      False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3327 passengers were Transported\n",
      "3279 passeners were NOT transported\n"
     ]
    }
   ],
   "source": [
    "#check label distribution\n",
    "print(str(data[data[\"Transported\"] == True].shape[0]) + \" passengers were Transported\")\n",
    "print(str(data[data[\"Transported\"] == False].shape[0]) + \" passeners were NOT transported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data Processing + Feature Engineering\n",
    "Before we start building and training our model, we have to process our dataset a bit to get it ready for input to the model. More specifically, we should aim to do a few things:\n",
    "\n",
    "1. Remove unnecessary features\n",
    "2. Scale features\n",
    "3. Encode categorical data (categorical --> numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unnecessary Features\n",
    "More often than not, there will be features we know will not help us predict our label. While doing so requires some domain knowledge, in this case, we will make some assumptions. We will remove the following features first:\n",
    "\n",
    "1. ```PassengerId```\n",
    "2. ```Name```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the PassengerId and Name columns from the dataset\n",
    "data = data.drop([\"PassengerId\", \"Name\"], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another time we may want to remove features, is if they would be too difficult to encode into numerical data. This might include long text data (reviews, comments), or categorical data with too many categories (high cardinality, different possible values). \n",
    "\n",
    "Let's take a look at the ```Cabin``` column. Getting all the unique values, we see that there are about 5305 different cabins. In this case, it might be best to remove the ```Cabin``` feature from out dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5305"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check number of unique cabins\n",
    "data[\"Cabin\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Cabin column from dataset\n",
    "data = data.drop([\"Cabin\"], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (Encoding)\n",
    "Now that we've removed all the features we needed, let's move on to encoding our categorical variables. \n",
    "\n",
    "The most popular method is One-hot Encoding, and it is the one we will use. However, know that for different situations, we may want to use other methods of encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode 'Destination' and 'HomePlanet' columns\n",
    "encoded = pd.get_dummies(data[[\"Destination\", \"HomePlanet\"]], drop_first=True, dtype=int)\n",
    "data.drop([\"Destination\", \"HomePlanet\"], axis=1, inplace=True)\n",
    "data = data.join(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing, we need to label encode our True/False columns. We'll denote 0 for False, and 1 for True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encode CryoSleep, VIP, and Transported columns\n",
    "data['CryoSleep'] = data['CryoSleep'].map(lambda val: 1 if val else 0)\n",
    "data['VIP'] = data['VIP'].map(lambda val: 1 if val else 0)\n",
    "data['Transported'] = data['Transported'].map(lambda val: 1 if val else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset is all cleaned and processed, let's move onto modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6606 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall     Spa  \\\n",
       "0             0  39.0    0          0.0        0.0           0.0     0.0   \n",
       "1             0  24.0    0        109.0        9.0          25.0   549.0   \n",
       "2             0  58.0    1         43.0     3576.0           0.0  6715.0   \n",
       "3             0  33.0    0          0.0     1283.0         371.0  3329.0   \n",
       "4             0  16.0    0        303.0       70.0         151.0   565.0   \n",
       "...         ...   ...  ...          ...        ...           ...     ...   \n",
       "6601          0  41.0    1          0.0     6819.0           0.0  1643.0   \n",
       "6602          1  18.0    0          0.0        0.0           0.0     0.0   \n",
       "6603          0  26.0    0          0.0        0.0        1872.0     1.0   \n",
       "6604          0  32.0    0          0.0     1049.0           0.0   353.0   \n",
       "6605          0  44.0    0        126.0     4688.0           0.0     0.0   \n",
       "\n",
       "      VRDeck  Transported  Destination_PSO J318.5-22  Destination_TRAPPIST-1e  \\\n",
       "0        0.0            0                          0                        1   \n",
       "1       44.0            1                          0                        1   \n",
       "2       49.0            0                          0                        1   \n",
       "3      193.0            0                          0                        1   \n",
       "4        2.0            1                          0                        1   \n",
       "...      ...          ...                        ...                      ...   \n",
       "6601    74.0            0                          0                        0   \n",
       "6602     0.0            0                          1                        0   \n",
       "6603     0.0            1                          0                        1   \n",
       "6604  3235.0            0                          0                        0   \n",
       "6605    12.0            1                          0                        1   \n",
       "\n",
       "      HomePlanet_Europa  HomePlanet_Mars  \n",
       "0                     1                0  \n",
       "1                     0                0  \n",
       "2                     1                0  \n",
       "3                     1                0  \n",
       "4                     0                0  \n",
       "...                 ...              ...  \n",
       "6601                  1                0  \n",
       "6602                  0                0  \n",
       "6603                  0                0  \n",
       "6604                  1                0  \n",
       "6605                  1                0  \n",
       "\n",
       "[6606 rows x 13 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Creating Training, Validation, and Testing Datasets\n",
    "\n",
    "The following command splits a given dataset into two distinct sets (training and testing): \n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "```\n",
    "* `X` is the set of feature variables in the dataset\n",
    "* `y` is the target variable in the dataset \n",
    "* `test_size` is the fraction of the original dataset that should be reserved for the testing\n",
    "\n",
    "**Note** Typically in machine learning we also perform what is called validation. Validation during training is like giving \"mini\" tests during the learning process. Typically validation helps with preventing the model from overfitting during training. For the sake of this workshop, we won't be covering validation but I encourage you to still read up about it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, separate features from label\n",
    "X = data.drop(\"Transported\", axis=1, inplace=False) #every column except the label\n",
    "y = data[\"Transported\"] #just the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `X` and `y` to perform the `train_test_split` to obtain your training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type your answer here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing, it is always good practice to standardize our data before modeling. This ensures that all our numerical data is on the same scale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit scaler to our training set\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use transform scale both the training and test set\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 4954\n",
      "Size of test set: 1652\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training set: \" + str(X_train.shape[0]))\n",
    "print(\"Size of test set: \" + str(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Modeling\n",
    "When modeling in machine learning, we rarely only use one model! In this case, we'll be trying a few different models:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Support Vector Classifier\n",
    "3. Decision Tree\n",
    "\n",
    "Note, there are many, many different models for classification. These are some of the more popular ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let's start by creating a simple logistic regression model. We can import it and create an instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type your answer here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(solver=\"saga\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit\n",
    "After we've created our model, we now need to train it using our training set. Use `.fit(X_train, y_train)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='saga')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type your answer here\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "Now that the model has been trained, we can test its performance using the test set. Use `.predict(X_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions from test set\n",
    "lr_predicted = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "There are many ways to evaluate how well our model performs. These methods vary between classification and regression as well. \n",
    "\n",
    "For classification, a very popular and intuitive metric is the accuracy, which is simply the percentage of observations that the model correctly classified (predicted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use `accuracy_score(...)` to obtain the accuracy of our model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type your answer here\n",
    "lr_accuracy = accuracy_score(y_test, lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression achieved an accuracy of: 77.66%!\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression achieved an accuracy of: \" + str(round(lr_accuracy *100, 2)) + \"%!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, other popular metrics are the F1-Score, Recall and Precision. We can use a confusion matrix to obtain these values.\n",
    "\n",
    "Use `classification_report(...)` to obtain the confusion matrix and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.765882</td>\n",
       "      <td>0.776634</td>\n",
       "      <td>0.776956</td>\n",
       "      <td>0.777023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.760529</td>\n",
       "      <td>0.792935</td>\n",
       "      <td>0.776634</td>\n",
       "      <td>0.776732</td>\n",
       "      <td>0.776634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.774036</td>\n",
       "      <td>0.779174</td>\n",
       "      <td>0.776634</td>\n",
       "      <td>0.776605</td>\n",
       "      <td>0.776589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>831.000000</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>0.776634</td>\n",
       "      <td>1652.000000</td>\n",
       "      <td>1652.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.788030    0.765882  0.776634     0.776956      0.777023\n",
       "recall       0.760529    0.792935  0.776634     0.776732      0.776634\n",
       "f1-score     0.774036    0.779174  0.776634     0.776605      0.776589\n",
       "support    831.000000  821.000000  0.776634  1652.000000   1652.000000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type your answer here\n",
    "mtrx = pd.DataFrame(classification_report(y_test, lr_predicted, output_dict=True))\n",
    "mtrx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Besides evaluation, interpretation is also a key step. Given our model and its output, what can we deduce from it? For example:\n",
    "1. What are the most important features towards determining whether a passenger was transported or not?\n",
    "2. What are the least important features?\n",
    "\n",
    "This idea is called feature importance. Typically there's a trade-off between interpretability of a model and its complexity. \n",
    "\n",
    "Use your model's `.coef_[0]` attribute to get the feature coefficients. Put them alongside the name of the features (hint: use a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HomePlanet_Europa</td>\n",
       "      <td>0.964970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FoodCourt</td>\n",
       "      <td>0.860186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CryoSleep</td>\n",
       "      <td>0.625439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ShoppingMall</td>\n",
       "      <td>0.393804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HomePlanet_Mars</td>\n",
       "      <td>0.278842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VIP</td>\n",
       "      <td>-0.130018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.142180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Destination_PSO J318.5-22</td>\n",
       "      <td>-0.160249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Destination_TRAPPIST-1e</td>\n",
       "      <td>-0.273173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RoomService</td>\n",
       "      <td>-0.932039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VRDeck</td>\n",
       "      <td>-2.066204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spa</td>\n",
       "      <td>-2.145932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         coef    weight\n",
       "10          HomePlanet_Europa  0.964970\n",
       "4                   FoodCourt  0.860186\n",
       "0                   CryoSleep  0.625439\n",
       "5                ShoppingMall  0.393804\n",
       "11            HomePlanet_Mars  0.278842\n",
       "2                         VIP -0.130018\n",
       "1                         Age -0.142180\n",
       "8   Destination_PSO J318.5-22 -0.160249\n",
       "9     Destination_TRAPPIST-1e -0.273173\n",
       "3                 RoomService -0.932039\n",
       "7                      VRDeck -2.066204\n",
       "6                         Spa -2.145932"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type your answer here\n",
    "lr_coef = pd.DataFrame({\"weight\": lr_model.coef_[0]})\n",
    "lr_coef[\"coef\"] = X.columns\n",
    "lr_coef = lr_coef[[\"coef\", \"weight\"]]\n",
    "lr_coef.sort_values(by=\"weight\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the coefficient weights, we can tell that the most important feature (feature with the highest weight **magnitude**) are ```Spa```, ```VRDeck```, and ```HomePlanet_Europa```. Generally higher magnitude weights result in the weight having a stronger impact on the result of the prediction, whether it be negative or positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can do better with a more complex model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Validation with Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do something similar as above, except we will introduce a few more concepts:\n",
    "1. Validation\n",
    "2. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "In addition to a training and test set, we typically use a validation set to test and choose the best hyperparameters for our model. \n",
    "\n",
    "Hyperparameters are sort of like 'settings' for our model. Each model has a variety of different hyperparameters that tune and affect the performance of the model. When validating hyperparameters, we normally instantiate lists of possible hyperparameter values, and iterate through each possible combination and testing the model accuracy. We keep track of the combination of hyperparameter values that yield the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train-test-split on the training set to get the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.95% with C=0.01, gamma=0.01 and kernel=linear\n",
      "Accuracy: 75.95% with C=0.01, gamma=0.1 and kernel=linear\n",
      "Accuracy: 75.95% with C=0.01, gamma=0.15 and kernel=linear\n",
      "Accuracy: 75.95% with C=0.01, gamma=0.2 and kernel=linear\n",
      "Accuracy: 75.95% with C=0.01, gamma=0.3 and kernel=linear\n",
      "Accuracy: 76.76% with C=0.1, gamma=0.01 and kernel=linear\n",
      "Accuracy: 76.76% with C=0.1, gamma=0.1 and kernel=linear\n",
      "Accuracy: 76.76% with C=0.1, gamma=0.15 and kernel=linear\n",
      "Accuracy: 76.76% with C=0.1, gamma=0.2 and kernel=linear\n",
      "Accuracy: 76.76% with C=0.1, gamma=0.3 and kernel=linear\n",
      "Accuracy: 77.16% with C=0.25, gamma=0.01 and kernel=linear\n",
      "Accuracy: 77.16% with C=0.25, gamma=0.1 and kernel=linear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.16% with C=0.25, gamma=0.15 and kernel=linear\n",
      "Accuracy: 77.16% with C=0.25, gamma=0.2 and kernel=linear\n",
      "Accuracy: 77.16% with C=0.25, gamma=0.3 and kernel=linear\n",
      "Accuracy: 77.24% with C=0.5, gamma=0.01 and kernel=linear\n",
      "Accuracy: 77.24% with C=0.5, gamma=0.1 and kernel=linear\n",
      "Accuracy: 77.24% with C=0.5, gamma=0.15 and kernel=linear\n",
      "Accuracy: 77.24% with C=0.5, gamma=0.2 and kernel=linear\n",
      "Accuracy: 77.24% with C=0.5, gamma=0.3 and kernel=linear\n",
      "Accuracy: 77.32% with C=0.75, gamma=0.01 and kernel=linear\n",
      "Accuracy: 77.32% with C=0.75, gamma=0.1 and kernel=linear\n",
      "Accuracy: 77.32% with C=0.75, gamma=0.15 and kernel=linear\n",
      "Accuracy: 77.32% with C=0.75, gamma=0.2 and kernel=linear\n",
      "Accuracy: 77.32% with C=0.75, gamma=0.3 and kernel=linear\n",
      "Accuracy: 77.24% with C=1.0, gamma=0.01 and kernel=linear\n",
      "Accuracy: 77.24% with C=1.0, gamma=0.1 and kernel=linear\n",
      "Accuracy: 77.24% with C=1.0, gamma=0.15 and kernel=linear\n",
      "Accuracy: 77.24% with C=1.0, gamma=0.2 and kernel=linear\n",
      "Accuracy: 77.24% with C=1.0, gamma=0.3 and kernel=linear\n",
      "Accuracy: 75.06% with C=0.01, gamma=0.01 and kernel=rbf\n",
      "Accuracy: 72.56% with C=0.01, gamma=0.1 and kernel=rbf\n",
      "Accuracy: 73.69% with C=0.01, gamma=0.15 and kernel=rbf\n",
      "Accuracy: 74.33% with C=0.01, gamma=0.2 and kernel=rbf\n",
      "Accuracy: 75.14% with C=0.01, gamma=0.3 and kernel=rbf\n",
      "Accuracy: 75.87% with C=0.1, gamma=0.01 and kernel=rbf\n",
      "Accuracy: 76.67% with C=0.1, gamma=0.1 and kernel=rbf\n",
      "Accuracy: 76.43% with C=0.1, gamma=0.15 and kernel=rbf\n",
      "Accuracy: 76.43% with C=0.1, gamma=0.2 and kernel=rbf\n",
      "Accuracy: 75.95% with C=0.1, gamma=0.3 and kernel=rbf\n",
      "Accuracy: 76.35% with C=0.25, gamma=0.01 and kernel=rbf\n",
      "Accuracy: 77.4% with C=0.25, gamma=0.1 and kernel=rbf\n",
      "Accuracy: 77.32% with C=0.25, gamma=0.15 and kernel=rbf\n",
      "Accuracy: 77.24% with C=0.25, gamma=0.2 and kernel=rbf\n",
      "Accuracy: 77.0% with C=0.25, gamma=0.3 and kernel=rbf\n",
      "Accuracy: 76.51% with C=0.5, gamma=0.01 and kernel=rbf\n",
      "Accuracy: 78.37% with C=0.5, gamma=0.1 and kernel=rbf\n",
      "Accuracy: 77.8% with C=0.5, gamma=0.15 and kernel=rbf\n",
      "Accuracy: 77.32% with C=0.5, gamma=0.2 and kernel=rbf\n",
      "Accuracy: 77.0% with C=0.5, gamma=0.3 and kernel=rbf\n",
      "Accuracy: 76.43% with C=0.75, gamma=0.01 and kernel=rbf\n",
      "Accuracy: 78.45% with C=0.75, gamma=0.1 and kernel=rbf\n",
      "Accuracy: 77.97% with C=0.75, gamma=0.15 and kernel=rbf\n",
      "Accuracy: 77.32% with C=0.75, gamma=0.2 and kernel=rbf\n",
      "Accuracy: 77.48% with C=0.75, gamma=0.3 and kernel=rbf\n",
      "Accuracy: 76.59% with C=1.0, gamma=0.01 and kernel=rbf\n",
      "Accuracy: 78.21% with C=1.0, gamma=0.1 and kernel=rbf\n",
      "Accuracy: 77.8% with C=1.0, gamma=0.15 and kernel=rbf\n",
      "Accuracy: 77.64% with C=1.0, gamma=0.2 and kernel=rbf\n",
      "Accuracy: 77.4% with C=1.0, gamma=0.3 and kernel=rbf\n",
      "Accuracy: 47.7% with C=0.01, gamma=0.01 and kernel=poly\n",
      "Accuracy: 63.76% with C=0.01, gamma=0.1 and kernel=poly\n",
      "Accuracy: 76.43% with C=0.01, gamma=0.15 and kernel=poly\n",
      "Accuracy: 77.08% with C=0.01, gamma=0.2 and kernel=poly\n",
      "Accuracy: 77.32% with C=0.01, gamma=0.3 and kernel=poly\n",
      "Accuracy: 48.67% with C=0.1, gamma=0.01 and kernel=poly\n",
      "Accuracy: 76.51% with C=0.1, gamma=0.1 and kernel=poly\n",
      "Accuracy: 77.24% with C=0.1, gamma=0.15 and kernel=poly\n",
      "Accuracy: 77.16% with C=0.1, gamma=0.2 and kernel=poly\n",
      "Accuracy: 78.53% with C=0.1, gamma=0.3 and kernel=poly\n",
      "Accuracy: 49.39% with C=0.25, gamma=0.01 and kernel=poly\n",
      "Accuracy: 77.24% with C=0.25, gamma=0.1 and kernel=poly\n",
      "Accuracy: 77.24% with C=0.25, gamma=0.15 and kernel=poly\n",
      "Accuracy: 77.97% with C=0.25, gamma=0.2 and kernel=poly\n",
      "Accuracy: 78.45% with C=0.25, gamma=0.3 and kernel=poly\n",
      "Accuracy: 50.36% with C=0.5, gamma=0.01 and kernel=poly\n",
      "Accuracy: 77.08% with C=0.5, gamma=0.1 and kernel=poly\n",
      "Accuracy: 77.89% with C=0.5, gamma=0.15 and kernel=poly\n",
      "Accuracy: 78.69% with C=0.5, gamma=0.2 and kernel=poly\n",
      "Accuracy: 77.8% with C=0.5, gamma=0.3 and kernel=poly\n",
      "Accuracy: 50.85% with C=0.75, gamma=0.01 and kernel=poly\n",
      "Accuracy: 77.24% with C=0.75, gamma=0.1 and kernel=poly\n",
      "Accuracy: 78.37% with C=0.75, gamma=0.15 and kernel=poly\n",
      "Accuracy: 78.69% with C=0.75, gamma=0.2 and kernel=poly\n",
      "Accuracy: 77.48% with C=0.75, gamma=0.3 and kernel=poly\n",
      "Accuracy: 51.57% with C=1.0, gamma=0.01 and kernel=poly\n",
      "Accuracy: 77.32% with C=1.0, gamma=0.1 and kernel=poly\n",
      "Accuracy: 78.61% with C=1.0, gamma=0.15 and kernel=poly\n",
      "Accuracy: 78.29% with C=1.0, gamma=0.2 and kernel=poly\n",
      "Accuracy: 77.8% with C=1.0, gamma=0.3 and kernel=poly\n",
      "BEST Accuracy: 78.69% with C=0.5, gamma=0.2 and kernel=poly\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter grid\n",
    "C = [0.01, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "gamma = [0.01, 0.1, 0.15, 0.2, 0.3]\n",
    "kernels = [\"linear\", \"rbf\", \"poly\"]\n",
    "\n",
    "#keep track of best accuracy, best parameters\n",
    "best_svc = None\n",
    "best_val_acc = 0.0\n",
    "best_C, best_gamma, best_kernel = None,None,None\n",
    "\n",
    "#loop through each possible hyperparameter combination\n",
    "for kernel in kernels:\n",
    "    for c in C:\n",
    "        for gamm in gamma:\n",
    "            #create an SVC model using the hyperparameters\n",
    "            #fit the model\n",
    "            #get predictions from the validation set\n",
    "            #get the accuracy from the validation set (call it svc_accuracy)\n",
    "            # ---- type your answer here --- \n",
    "            svc_model = SVC(kernel=kernel, class_weight=\"balanced\", C=c, gamma=gamm)\n",
    "            svc_model.fit(X_train, y_train)\n",
    "            svc_predicted = svc_model.predict(X_val)\n",
    "            svc_accuracy = accuracy_score(y_val, svc_predicted)\n",
    "            # --- type your answer here ---\n",
    "            \n",
    "            print(\"Accuracy: \" + str(round(svc_accuracy *100, 2)) + \"% with C=\" + str(c) + \", gamma=\" + str(gamm) + \" and kernel=\" + kernel)\n",
    "            \n",
    "            #check to see if accuracy improved\n",
    "            if svc_accuracy > best_val_acc:\n",
    "                best_svc = svc_model\n",
    "                best_val_acc = svc_accuracy\n",
    "                best_kernel = kernel\n",
    "                best_C = c\n",
    "                best_gamma = gamm\n",
    "                \n",
    "print(\"BEST Accuracy: \" + str(round(best_val_acc*100, 2)) + \"% with C=\" + str(best_C) + \", gamma=\" + str(best_gamma) + \" and kernel=\" + best_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well our **validated** model performs on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions from test set\n",
    "svc_pred = best_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's get our model accuracy\n",
    "svc_test_accuracy = accuracy_score(y_test, svc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC achieved an accuracy of: 78.39%!\n"
     ]
    }
   ],
   "source": [
    "print(\"SVC achieved an accuracy of: \" + str(round(svc_test_accuracy*100, 2)) + \"%!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Your turn! Let's do everything one more time, now with the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try it yourself!\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_predicted = dt_model.predict(X_val)\n",
    "dt_accuracy = accuracy_score(y_val, dt_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classsifier achieved an accuracy of: 0.72%!\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classsifier achieved an accuracy of: \" + str(round(dt_accuracy, 2)) + \"%!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's a wrap!\n",
    "There are **many** more types of models used for classification, as well as different metrics used to capture model performance. While we only went through a few, we encourage you to seek out more models on the Scikit-learn documentation!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
